{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS486 - Artificial Intelligence\n",
    "## Lesson 3 - Informed Search\n",
    "\n",
    "We can improve tree search with knowledge about the problem domain. For example, for US currency, returning the largest coin that doesn't exceed the goal always will always produce an optimal result. So how can we apply that knowledge to our change problem? \n",
    "\n",
    "First, we'll need to import the AIMA search library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import counter\n",
    "from aima.search import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Search\n",
    "\n",
    "The **`greedy_best_first_graph_search`** function takes a heuristic function that estimates the cost expanding the node. It's *greedy* because it *always* chooses the path with the cheapest cost according to the heuristic. Let's try running a greedy search against our **`Change`** problem from the previous lesson.\n",
    "\n",
    "First, enter your **`Change`** class from the last time in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change class goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use the **`greedy_best_first_graph_search`** function to search your Change tree for a solution. The search function takes two arguments: The problem instance and a heuristic. The heuristic takes a **`Node`** object that encodes the current node in the tree, the action that lef to the node, and the node's corresponding state. Here's what the **`Node`** class looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdoc Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code that implements a heuristic that always returns 1. Edit the **`heuristic`** function so that it always selects nodes with the highest value. \n",
    "\n",
    "**Hint:** `node.state` contains the list of coins for the state we're calculating the heuristic for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(node):\n",
    "    return 1\n",
    "\n",
    "change = Change(initial=(),goal=51)\n",
    "greedy_best_first_graph_search(change, heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same code from last the Uniformed Search lesson, we can see how greedy search performs by adding it to the list of searches below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches = [\n",
    "    breadth_first_tree_search,    \n",
    "    iterative_deepening_search,\n",
    "    uniform_cost_search,\n",
    "    depth_first_tree_search\n",
    "]\n",
    "\n",
    "print(\"{:^26} {:^10} {:^16}\".format(\"Search Type\", \"Goal Tests\", \"Solution\"))\n",
    "\n",
    "for search in searches:\n",
    "    problem = Change(initial=(),goal=26)\n",
    "    result = search(change)\n",
    "    print(\"{:26} {:^11} {:20}\".format(search.__name__,problem.goal_test.count,str(result.solution())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\\* search\n",
    "Is greedy *always* better? Consider the problem below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarnivalChange(Change):\n",
    "    def coins(self):\n",
    "        return [1,3,4]\n",
    "\n",
    "print(\"{:^26} {:^10} {:^16}\".format(\"Search Type\", \"Goal Tests\", \"Solution\"))\n",
    "\n",
    "for search in searches:\n",
    "    change = CarnivalChange(initial=(),goal=6)\n",
    "    result = search(change)\n",
    "    print(\"{:26} {:^11} {:20}\".format(search.__name__,change.goal_test.count,str(result.solution())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy seems to perform well but, in the **`CarnivalChange`** case, isn't returning the optimal solution. So how do we get the performance of a greedy search with the accuracy of Uniform Cost Search? The answer is **A\\* search**. \n",
    "\n",
    "The A* algorithm takes both a heuristic function and the path cost and adds the two together:\n",
    "\n",
    "\\begin{equation*}\n",
    "f(n) = g(n) + h(n)\n",
    "\\end{equation*}\n",
    "\n",
    "A\\* is guarenteed to return the optimal path is the heuristic is ***admissible***, meaning that is never over-estimates the cost to the goal. Consider the following questions before continuing:\n",
    "\n",
    "* Is our heuristic admissible? Why or why not?\n",
    "* What is the path cost of our **`Change`** problem? Can we change it? Do we need to?\n",
    "\n",
    "The AIMA **`astar_search`** operates exactly like the **`greedy_best_first_graph_search`** function: It takes a problem isntance and a heuristic function. Using the code above as a reference, run A\\* against the **`CarnivalChange`** problem and answer the following questions:\n",
    "\n",
    "* Does A\\* find the optimal solution? \n",
    "* How does A\\* perform compared to the other search algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run A* against CarnivalChange and evaluate its performance here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
