{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS486 - Artificial Intelligence\n",
    "## Lesson 23 - Hidden Markov Models \n",
    "\n",
    "Markov Chains gave us a way to estimate the probability distribution over a set of random variables over time. **Hidden Markov Models (HMMs)** are Markov Chains that incorporate evidence about the **hidden variables** we cannot directly observe. HMMs have the following components:\n",
    "\n",
    "* An initial (prior) distribution: $X_0$. Usually uniform. \n",
    "* A **stationary transition model**: $P(X_t\\mid{X_{t-1}})$.\n",
    "* An **emission model** that gives the probability of seeing evidence for a state: $P(e\\mid{X_{t-1}})$.\n",
    "\n",
    "### The Sad Grad\n",
    "\n",
    "First, let's walk through the example from the lecture. You are a gad student that never goes outside. The only evidence you have of rain is seeing someone carrying an umbrella. Here is what we are given:\n",
    "\n",
    "![Sad Grad Models](images/sad_grad_models.png)\n",
    "\n",
    "Now, here are the first three states if an umbrella is always observed:\n",
    "\n",
    "![Sad Grad](images/sad_grad.png)\n",
    "\n",
    "### Time Diminishes Beliefs\n",
    "\n",
    "If you don't see anybody with or without an umbrella, you will eventually return to the 50/50 belief that it might be raining. Each time step brings your probability vector closer to the stationary distribution of the transition model. \n",
    "\n",
    "Your current probability vector always includes whatever evidence you've seen to date and at each time step you compute the new vector based on the transition model and the current vector:\n",
    "\n",
    "$$ P(X_{t+1}\\mid{e_{1:t}})=\\sum_{x_t}P(X_{t+1}\\mid{x_t})P(x_t\\mid{e_{1:t}}) $$\n",
    "\n",
    "It gets cumbersome to carry the evidence everywhere we go, so we'll call a **belief** the probability given all of the evidence to date:\n",
    "\n",
    "$$ B(X_{t+1}) = P(X_t\\mid{e_{1:t}}) $$\n",
    "$$ B'(X_{t+1})=\\sum_{x_t}P(X'\\mid{x})B(x_t) $$\n",
    "\n",
    "### Evidence Strengthens Beliefs\n",
    "\n",
    "Every time someone walks by with an umbrella, your belief that it is raining goes up:\n",
    "\n",
    "$$ B'(X_{t+1}) = P(X_{t+1}\\mid{e_{1:t}}) $$\n",
    "$$ P(X_{t+1}\\mid{e_{1:t+1}}) \\propto  P(e_{t+1}\\mid{X_{t+1}})P(X_{t+1}\\mid{e_{1:t}}) $$\n",
    "\n",
    "So our new beliefs are:\n",
    "\n",
    "$$ B(X_{t+1}) \\propto P(e\\mid{X_{t+1}})B'(X_{t+1}) $$\n",
    "\n",
    "Since the evidence is just a scalar, you need to normalize to get back to a proper probability distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Algorithm\n",
    "\n",
    "The **Forward Algorithm** incorporates both time steps and evidence into one update:\n",
    "\n",
    "$$P(x_t\\mid{e_{1:t}}) \\propto_{X} P(e_t\\mid{x_t})\\sum_{x_{t-1}}P(x_t\\mid{x_{t-1}})P(x_{t-1},e_{1:t-1})$$\n",
    "\n",
    "Note that the result is not normalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Filtering\n",
    "\n",
    "It's not always practical to keep track of every possible value a variable can take on in our HMM. Instead, generate a bunch of samples and let each sample have a vote toward a particular value for variable. \n",
    "\n",
    "For example, consider a robot in a 9x9 grid. A particle filter that approximates the robot's location might looks like this:\n",
    "\n",
    "![Particle Filtering](images/particles.png)\n",
    "\n",
    "Samples are referred to as *particles* and the more particles you have, the more accurate your approximation will be. \n",
    "\n",
    "Particle filtering can be divided into four steps:\n",
    "\n",
    "1. __Initialization__: \n",
    "<br>\n",
    "If we have some idea about the prior probability distribution, we drop the initial particles accordingly, or else we just drop them uniformly over the state space.\n",
    "\n",
    "2. __Forward pass__: \n",
    "<br>\n",
    "Every time step, loop through all our particles and try to simulate what could happen to each one of them by sampling its next position from the transition model. Since each sample can only make a single transition (this is no longer a probability distribution), uniformly pick a transition for each particle. Some sample will move, some may stay. \n",
    "\n",
    "3. __Reweight__:\n",
    "<br>\n",
    "Assign weights to each particle according to the evidence:\n",
    "<br>\n",
    "$$w(x) = P(e/x)$$\n",
    "$$B(X) \\propto P(e/X)B'(X)$$\n",
    "\n",
    "4. __Resample__:\n",
    "<br>\n",
    "Instead of trying to keep track of weighted samples, we _resample_.\n",
    "<br>\n",
    "Replace the weighted particles with the same number of new particles. Place the new particles according the weights of the previous particles. A highly probable particle will be replaced by numerous new particles and unlikely particles might not be replaced at all. \n",
    "<br>\n",
    "This is like re-normalizing the distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
