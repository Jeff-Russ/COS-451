{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS486 - Artificial Intelligence\n",
    "## Lesson 22 - Markov Models\n",
    "\n",
    "Start with an application, then work backwards. \n",
    "\n",
    "Bayes' rule - the most important equation in AI! Because data is noisy and probabilistic reasoning is a way to deal with it. \n",
    "\n",
    "$$P(x|y) = \\frac{P(y|x)}{P(y)}P(x)$$\n",
    "\n",
    "> The essence of the Bayesian approach is to provide a mathematical rule explaining how you should change your existing beliefs in the light of new evidence. In other words, it allows scientists to combine new data with their existing knowledge or expertise. \n",
    "\n",
    "Example: Picking one out of the two coins at random would result in a 1/2 probability of having picked the fair coin. However, the question was, what is the probability of having picked the fair coin, GIVEN THAT the coin came up heads. The probability of having picked the fair coin is dependent on the evidence we have (it came up heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/Zxm4Xxvzohk?rel=0&showinfo=0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x107fcbe48>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('Zxm4Xxvzohk?rel=0&showinfo=0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to view: \n",
    "\n",
    "```\n",
    "                 likelihood * prior\n",
    "posterior = ------------------------------\n",
    "                  marginal likelihood\n",
    "```                  \n",
    "\n",
    "The denominator is just a normalizing constant that ensures the posterior adds up to 1; it can be computed by summing up the numerator over all possible values of R. If you don't normalize, you can write Bayes' rule as:\n",
    "\n",
    "$$ P(x\\mid{y}) \\propto P(y\\mid{x})P(x) $$\n",
    "\n",
    "## Independence\n",
    "\n",
    "$$ X{\\perp\\!\\!\\!\\perp}Y \\iff P(X,Y) = P(X)P(Y) = \\forall x,y P(x,y) = P(x)P(y) $$\n",
    "\n",
    "Example: The probability distribution of two coin flips. Not usually true, but a simplifying *modeling assumption*. \n",
    "\n",
    "## Conditional Independence \n",
    "\n",
    "Our most basic and robust form of knowledge about uncertain environments. \n",
    "\n",
    "A variable can be **conditionally independent** of another presented some evidence. Example, cavity and toothache are dependent, but catch is conditionally independent of toothache given cavity. So\n",
    "\n",
    "$$ P(Catch \\mid{Toothache,Cavity}) = P(Catch \\mid{Cavity}) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Models\n",
    "\n",
    "Value of $X$ at a given time is a **state**. Okay, so we're going to take a bunch of variables and connect them linearly. We can really simplify the distribution if we assume that variables not directly connect are independent. Not usually true, but we're looking for an approximation of reality. So the assumption is:\n",
    "\n",
    "$$ X_t {\\perp\\!\\!\\!\\perp} X_1,..,X_{t-2}\\mid{X_{t-1}} $$\n",
    "\n",
    "So we can write our distribution as:\n",
    "\n",
    "$$ P(X_1,X_2,...,X_T) = P(X_1)\\prod_{t=2}^T P(X_t|X_{t-1})$$\n",
    "\n",
    "Second assumption: Transition model doesn't change (stationary). In other words, $P(X_t\\mid{X_{t-1}})$ doesn't change. \n",
    "\n",
    "Taking a step: Compute the marginal for the next time step. Use the table or graph, but just look up values. \n",
    "\n",
    "## Mini-forward algorithm\n",
    "\n",
    "$$ P(x_1) = given$$\n",
    "$$ P(x_t) = \\sum_{x_{t-1}}P(x_t\\mid{x_{t-1}})P(x_{t-1})$$\n",
    "\n",
    "Iterating converges to the **stationary distribution**, $P_{\\infty}$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
