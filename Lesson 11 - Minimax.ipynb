{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS486 - Artificial Intelligence\n",
    "## Lesson 11 - Minimax\n",
    "\n",
    "In adversarial search, our agent only gets to choose some portion of the path to the goal. How does that impact our search? We'll walk through a few examples of finding the best path to goal in the presence of an adversary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import nim_decision_tree\n",
    "from aima.games import *\n",
    "from aima.notebook import psource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nim\n",
    "\n",
    "Nim is a game in which two players are given a pile of objects and take turns taking 1 to $n$ objects from the pile. The player that takes the last object loses.  \n",
    "\n",
    "To make it a little more interesting, let's say that the winner's score is the number of objects that their ** *opponent* ** took. In other words, you want to win the game having taken the fewest number of objects possible. We'll call our variation of the game *Mini*nim. Here's an implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mininim(Game):\n",
    "    def __init__(self,objects,moves):\n",
    "        self.moves = list(range(1,moves+1))\n",
    "        self.initial = GameState(to_move=1,utility=0,board=objects,moves=self.moves)\n",
    "    \n",
    "    def actions(self,state):\n",
    "        return [x for x in self.moves if x <= state.board]\n",
    "    \n",
    "    def result(self,state,action):\n",
    "        to_move=state.to_move%2+1\n",
    "        \n",
    "        # we save the number of objects player 1 has \n",
    "        # taken as the utility in the game state.\n",
    "        if state.to_move == 1:\n",
    "            utility=state.utility+action\n",
    "        else:\n",
    "            utility=state.utility\n",
    "        \n",
    "        board=state.board-action\n",
    "        moves=[x for x in self.moves if x <= board]\n",
    "        \n",
    "        return GameState(to_move,utility,board,moves)\n",
    "    \n",
    "    def utility(self,state,player):\n",
    "        if state.to_move == 1:\n",
    "            score = self.initial.board - state.utility\n",
    "        else:\n",
    "            score = -state.utility\n",
    "            \n",
    "        return (score if player == 1 else -score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Search\n",
    "\n",
    "Consider the following decision tree for a Mininim game with three objects and two players that alternate in taking one or two objects from the pile at a time. Which path yields the highest score? What is the best opening move for the first player? Why aren't they the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim_decision_tree(objects=3,moves=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's play the 3-pile game from the decision tree above with two random players. The output of the play is **player 1's** score. It's negative if player 1 loses. Let's see a few games against random players:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mininim.play_game(query_player,random_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Nim\n",
    "\n",
    "There are three kinds of player that can play AIMA games:\n",
    "\n",
    "* `random_player`: Plays a random action\n",
    "* `minimax_player`: Defined below. Does an exhaustive search of the minimax tree and moves accordingly. \n",
    "* `query_player`: Queries you for a play.\n",
    "* `alphabeta_player`: Minimax player with alpha beta pruning. \n",
    "\n",
    "We'll play a 5-pile game with each kind of player. The output of the play is player 1's score. It's negative if player 1 loses. First, a random player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mininim = Mininim(objects=5,moves=2)\n",
    "mininim.play_game(query_player,random_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimax_player = lambda game,state: minimax_decision(state,game)\n",
    "mininim.play_game(query_player,minimax_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimax_player = lambda game,state: minimax_decision(state,game)\n",
    "mininim.play_game(minimax_player,query_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha-Beta Pruning \n",
    "\n",
    "So what's the difference between the minimax player and the alphabeta pruning player? Run the blocks below that time how long it takes the player to decide their first move:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "large_pile_mininim = Mininim(objects=30,moves=3)\n",
    "move = alphabeta_search(mininim.initial,large_pile_mininim)\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "large_pile_mininim = Mininim(objects=30,moves=3)\n",
    "move = minimax_decision(large_pile_mininim.initial,mininim)\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the difference? Pruning plays a huge role in how deep an agent can search. Working from the left to right, label the value of each node in the decision tree below. How far do you get before you can start to prune?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim_decision_tree(objects=5,moves=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fun variation on Nim is [Race to 50](https://mindyourdecisions.com/blog/2013/03/12/dice-game-race-to-50-video/). Just make sure you go first :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
